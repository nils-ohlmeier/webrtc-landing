<html><head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
  <title>Simple RTCPeerConnection Video Test</title>
  <style>
    #player1 {
      position:relative;
      width:640px;
      height:480px;
      float:right;
    }
    #player2 {
      position:relative;
      width:640px;
      height:480px;
      float:left;
    }
    #mainvideo {
      position:absolute;
      top:0;
      left:0;
      z-index:0;
    }
    #localvideo1, #localvideo2 {
      position:absolute;
      top:0;
      left:0;
      z-index:1;
    }

    .hidden 
    {
      display: none;
    }
  </style>
</head>
<body>

<center>
<a href="index.html">Main webrtc demo
page</a><br>
<h2>Simple canvas.captureStream() Test</h2>
<b>NOTE: You need Firefox 41, and set canvas.capturestream.enabled to true in about:config!</b><br>
Hint: Poke at the mesh after hitting 'Start'
</center>
<div>
<button id="tehbutton" onclick="xstart();">Start!</button>
<button id="swap" onclick="replace_track(pc1)">Swap video</button>
<div id="controls" class="hidden">
<input type="checkbox" id="audio_only" value="Audio-only call">
<label for="audio_only">Audio-only call</label>
<input type="checkbox" id="disable_video" value="Disable video" onclick="disable_media(pc1, 1, 0);">
<label for="disable_video">Disable video</label>
<input type="checkbox" id="disable_audio" value="Disable audio" onclick="disable_media(pc1, 0, 0);">
<label for="disable_audio">Disable audio</label>
<input type="checkbox" id="requireh264" value="Require H.264" onclick="h264StateChange(this);">
<label for="requireh264">Require H.264 video</label>
<input type="checkbox" id="requireg722" value="Require G.722">
<label for="requireg722">Require G.722 audio</label>
<div id="divH264" class="hidden">
  <br>
  <input type="checkbox" id="prefermode0" value="Prefer Mode 0">
  <label for="prefermode0">Prefer H.264 Mode 0</label>
</div>
</div><br>
<div>
<div id="player1">
<canvas id="c"></canvas>
<video tabindex="0" id="localvideo1" controls="controls" height="120" width="160" muted></video></div>
<div id="player2">
<video tabindex="0" id="pc2video" class="mainvideo" controls="controls" height="350" width="560" muted autoplay></video>
<br style="clear: left;" />
</div>
<div id="log"></div>

<script type="text/javascript" src="Cloth.js"></script>

<script type="application/javascript;version=1.8">
  // Lame clone function. Not efficient but we don't have jQuery.
  function copy_dictionary (obj) {
    return JSON.parse(JSON.stringify(obj));
  }

  function log(msg) {
    let div = document.getElementById("log");
    div.innerHTML = div.innerHTML + "<p>" + msg + "</p>";
  }

  let mycanvas = document.getElementById("c");
  mycanvas.id = 'source_canvas';

  let pc2video = document.getElementById("pc2video");
  pc2video.onplay = function() {};

  let button = document.getElementById("tehbutton");
  let localvideo1 = document.getElementById("localvideo1");
  let swapped = false;
  let audio_only = document.getElementById("audio_only");
  audio_only.checked = false;
  let video_disable = document.getElementById("disable_video");
  let audio_disable = document.getElementById("disable_audio");
  let requireh264 = document.getElementById("requireh264");
  requireh264.checked = false;
  let prefermode0 = document.getElementById("prefermode0");
  prefermode0.checked = false;
  let requireg722 = document.getElementById("requireg722");
  requireg722.checked = false;

  let pc1;
  let pc2;

  let pc1_offer;
  let pc2_answer;

  let offer_constraints;
  let answer_constraints;

  let fake_stream;
  let real_stream;
  let new_stream;

  var senders1 = [ ];
  var senders2 = [ ];

  function failed(code) {
    log("Failure callback: " + JSON.stringify(code));
  }

  function disable_media(pc, type, array_index) {
    log("disable_media");
    var stream;
    if (pc == pc1)
      stream = localvideo1.mozSrcObject;
    else if (pc == pc2)
      ;//stream = localvideo2.mozSrcObject;
    else log("bad pc " + pc);

    if (stream) {
      log("track[" + array_index + "] = " + stream.getVideoTracks()[array_index]);
      if (type == 1)
        stream.getVideoTracks()[array_index].enabled = !video_disable.checked;
      else if (type == 0)
        stream.getAudioTracks()[array_index].enabled = !audio_disable.checked;
      else
        log("bad type");
    }
    else
      log("no stream");
  }

  function replace_track(pc) {
    swapped = !swapped;
    //log("replace_track = " + swapped);

    //senders1['audio'].replaceTrack(fake_stream.getAudioTracks()[0], function() {}, failed);
    localvideo1.mozSrcObject = fake_stream;
    localvideo1.play();
    let old_video = senders1['video'].track;
    //log(old_video);
    senders1['video'].replaceTrack(fake_stream.getVideoTracks()[0], function() {});
    //log("Replaced video with fake");
    let temp = real_stream;
    real_stream = fake_stream;
    fake_stream = temp;
  }

  // pc1.createOffer finished, call pc1.setLocal
  function step1(offer) {
//    log("Offer:  " + sdpPrettyPrint(offer.sdp));
    pc1_offer = offer;

    if (requireh264.checked) {
      // to enforce the usage of H264 we remove the VP8 codec from the offer
      offer.sdp = removeVP8(offer.sdp);
      if (prefermode0.checked) {
        offer.sdp = preferMode0(offer.sdp);
      }
      pc1_offer = offer;
//      log("No VP8 Offer: " + sdpPrettyPrint(offer.sdp));

      if (!offer.sdp.match(/a=rtpmap:[0-9]+ H264/g)) {
        log("No H264 found in the offer!!!");
        return;
      }
    }
    if (requireg722.checked) {
      // to enforce the usage of G.722 we remove other codecs from the offer
      offer.sdp = removeNonG722(offer.sdp);
      pc1_offer = offer;
      log("G.722 only Offer: " + sdpPrettyPrint(offer.sdp));

      if (!offer.sdp.match(/a=rtpmap:[0-9]+ G722/g)) {
        log("No G722 found in the offer!!!");
        return;
      }
    }
    pc1.setLocalDescription(offer, step2, failed);
  }

  // replace CR NL with HTML breaks
  function sdpPrettyPrint(sdp) {
    return sdp.replace(/[\r\n]+/g, '<br>');
  }

  function h264StateChange(cb)
  {
    var h264opts = document.getElementById('divH264'); 
    if(cb.checked){
      h264opts.style.display = 'block'; 
    } else {
      h264opts.style.display = 'none';
    }
  }

  // Also remove mode 0 if it's offered
  // Note, we don't bother removing the fmtp lines, which makes a good test
  // for some SDP parsing issues.
  function removeVP8(sdp) {
    updated_sdp = sdp.replace("a=rtpmap:120 VP8/90000\r\n","");
    updated_sdp = updated_sdp.replace(/m=video ([0-9]+) RTP\/SAVPF ([0-9 ]*) 120/g, "m=video $1 RTP\/SAVPF $2");
    updated_sdp = updated_sdp.replace(/m=video ([0-9]+) RTP\/SAVPF 120([0-9 ]*)/g, "m=video $1 RTP\/SAVPF$2");
    updated_sdp = updated_sdp.replace("a=rtcp-fb:120 nack\r\n","");
    updated_sdp = updated_sdp.replace("a=rtcp-fb:120 nack pli\r\n","");
    updated_sdp = updated_sdp.replace("a=rtcp-fb:120 ccm fir\r\n","");
    return updated_sdp;
  }

  // Remove anything that's not G.722 from the m=audio line
  function removeNonG722(sdp) {
    updated_sdp = sdp.replace(/m=audio ([0-9]+) RTP\/SAVPF ([0-9 ]*)/g, "m=audio $1 RTP\/SAVPF 9");
    return updated_sdp;
  }

  function preferMode0(sdp) {
    updated_sdp = updated_sdp.replace("126 97", "97 126");
    return updated_sdp;
  }

  // pc1.setLocal finished, call pc2.setRemote
  function step2() {
    pc1.onicecandidate = function(obj) {
      if (obj.candidate) {
//        log("pc1 found ICE candidate: " + JSON.stringify(obj.candidate));
        pc2.addIceCandidate(obj.candidate);
      } else {
//        log("pc1 got end-of-candidates signal");
      }
    }

    pc2.setRemoteDescription(pc1_offer, step3, failed);
  };

  // pc2.setRemote finished, call pc2.createAnswer
  function step3() {
    pc2.didSetRemote = true;
    while (pc2.ice_queued.length > 0) {
      pc2.addIceCandidate(pc2.ice_queued.shift());
    }
    pc2.createAnswer(step4, failed,  answer_constraints);
  }

  // pc2.createAnswer finished, call pc2.setLocal
  function step4(answer) {
//    log("Answer:  " + sdpPrettyPrint(answer.sdp));
    pc2_answer = answer;

    if ((requireh264.checked) && (!answer.sdp.match(/a=rtpmap:[0-9]+ H264/g))) {
      log("No H264 found in the answer!!!");
      return;
    }
    if ((requireg722.checked) && (!answer.sdp.match(/a=rtpmap:[0-9]+ G722/g))) {
      log("No G722 found in the answer!!!");
      return;
    }
    pc2.setLocalDescription(answer, step5, failed);
  }

  // pc2.setLocal finished, call pc1.setRemote
  function step5() {
    pc2.onicecandidate = function(obj) {
      if (obj.candidate) {
//        log("pc2 found ICE candidate: " + JSON.stringify(obj.candidate));
        pc1.addIceCandidate(obj.candidate);
      } else {
//        log("pc2 got end-of-candidates signal");
      }
    }

    pc1.setRemoteDescription(pc2_answer, step6, failed);
  }

  // pc1.setRemote finished, media should be running!
  function step6() {
    pc1.didSetRemote = true;
    while (pc1.ice_queued.length > 0) {
      pc1.addIceCandidate(pc1.ice_queued.shift());
    }
    //log("HIP HIP HOORAY");
  }

  function xstart() {
    button.innerHTML = "Stop!";
    button.onclick = stop;

    pc1 = new RTCPeerConnection();
    pc2 = new RTCPeerConnection();
    pc1.didSetRemote = false;
    pc2.didSetRemote = false;
    pc1.ice_queued = [];
    pc2.ice_queued = [];

    pc2.onicecandidate = function(obj) {
      if (obj.candidate) {
//        log("pc2 found ICE candidate: " + JSON.stringify(obj.candidate));
        if (pc1.didSetRemote) {
          pc1.addIceCandidate(obj.candidate);
        } else {
          pc1.ice_queued.push(obj.candidate);
        }
      } else {
//        log("pc2 got end-of-candidates signal");
      }
    }

    pc1.onicecandidate = function(obj) {
      if (obj.candidate) {
//        log("pc1 found ICE candidate: " + JSON.stringify(obj.candidate));
        if (pc2.didSetRemote) {
          pc2.addIceCandidate(obj.candidate);
        } else {
          pc2.ice_queued.push(obj.candidate);
        }
      } else {
//        log("pc1 got end-of-candidates signal");
      }
    }

    pc1.onaddstream = function(obj) {
      //log("pc1 got remote stream from pc2 " + obj.type);
      //pc1video.mozSrcObject = obj.stream;
      //setTimeout(pc1video.play, 1000);
    }
    pc2.onaddstream = function(obj) {
      //log("pc2 got remote stream from pc1 " + obj.type);
      pc2video.mozSrcObject = obj.stream;
      //setTimeout(pc2video.play, 1000);
    }

    var myrequest = { audio: true };
    if (!(audio_only.checked)) {
      myrequest = { audio: true, video: true };
    }

    myrequest_reverse = copy_dictionary(myrequest);

    offer_constraints = { mandatory: { OfferToReceiveVideo : false,
                                       OfferToReceiveAudio: false } };
    answer_constraints = { mandatory: { OfferToReceiveVideo : true,
                                        OfferToReceiveAudio: true } };

    navigator.mediaDevices.getUserMedia(myrequest, function(stream) {
      fake_stream = stream;

      start_cloth(mycanvas);

      real_stream = mycanvas.captureStream(15);
      localvideo1.mozSrcObject = real_stream;
      if (video_disable.checked)
        localvideo1.mozSrcObject.getVideoTracks()[0].enabled = false;
      if (audio_disable.checked)
        localvideo1.mozSrcObject.getAudioTracks()[0].enabled = false;
      localvideo1.play();
      real_stream.getTracks().forEach(function(track) {
         senders1[track.kind] = pc1.addTrack(track, real_stream);
      });
      pc1.createOffer(step1, failed, offer_constraints );
    }, failed);
  }

  function stop() {
    pc1.close();
    pc2.close();
    pc1 = null;
    pc2 = null;
    real_stream.getTracks().forEach(function(track) {
      track.stop();
    });
    fake_stream.getTracks().forEach(function(track) {
      track.stop();
    });
    localvideo1.mozSrcObject = null;
    pc2video.mozSrcObject = null;
    real_stream = null;
    fake_stream = null;
    swapped = false;

    button.innerHTML = "Start!";
    button.onclick = xstart;
  }
</script>


</body></html>
